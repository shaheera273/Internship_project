{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1370c95-1e6f-45a3-b4fd-0758dc927b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import gspread\n",
    "from gspread_dataframe import set_with_dataframe\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a4f8a85-da11-480b-ab36-7cf476cf6277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to account: 48690778, Server: HFMarketsGlobal-Demo\n"
     ]
    }
   ],
   "source": [
    "# Symbols to process\n",
    "symbols = [\"XAUUSD\", \"BTCUSD\", \"BTCEUR\", \"ETHUSD\", \"SOLUSD\", \"XRPUSD\", \n",
    "           \"DSHUSD\", \"XAUEUR\", \"GBPAUD\", \"GBPNZD\", \"CHFJPY\", \n",
    "           \"EURJPY\", \"USA30\", \"USA100\", \"USOIL\", \"UKOIL\", \"USDJPY\", \n",
    "           \"GBPJPY\", \"USA500\", \"UK100\", \"CADJPY\", \"AUDJPY\", \"GBPCHF\", \n",
    "           \"GBPCAD\", \"NZDJPY\", \"GBPUSD\", \"EURGBP\"]\n",
    "\n",
    "# Initialize MetaTrader 5\n",
    "if not mt5.initialize():\n",
    "    print(f\"MetaTrader 5 initialization failed with error code {mt5.last_error()}\")\n",
    "    exit()\n",
    "\n",
    "# Check account information\n",
    "account_info = mt5.account_info()\n",
    "if account_info is None:\n",
    "    print(\"Failed to connect to the trading account\")\n",
    "    mt5.shutdown()\n",
    "    exit()\n",
    "\n",
    "print(f\"Connected to account: {account_info.login}, Server: {account_info.server}\")\n",
    "\n",
    "# Function to find the last available trading day\n",
    "def get_last_trading_day(reference_date):\n",
    "    \"\"\"\n",
    "    Finds the most recent trading day that has data available.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        if reference_date.weekday() in [5, 6]:  # Skip Saturday (5) and Sunday (6)\n",
    "            reference_date -= timedelta(days=1)\n",
    "        else:\n",
    "            # Try fetching data for this date\n",
    "            start = datetime(reference_date.year, reference_date.month, reference_date.day, 0, 0)\n",
    "            end = start + timedelta(days=1)\n",
    "            for symbol in symbols:\n",
    "                rates = mt5.copy_rates_range(symbol, mt5.TIMEFRAME_D1, start, end)\n",
    "                if rates is not None and len(rates) > 0:\n",
    "                    return reference_date  # Found a valid trading day\n",
    "            reference_date -= timedelta(days=1)  # Try the previous day if no data found\n",
    "\n",
    "# Function to fetch trading data\n",
    "def fetch_trading_data(symbols):\n",
    "    \"\"\"\n",
    "    Fetch high, low, and level data for the given symbols over the past three days.\n",
    "    Handles weekends by using the most recent available data.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    now = datetime.now()\n",
    "\n",
    "    # Define labels and their respective reference days\n",
    "    days = [(\"C\", now), (\"Y\", now - timedelta(days=1)), (\"V\", now - timedelta(days=2))]\n",
    "\n",
    "    for symbol in symbols:\n",
    "        if not mt5.symbol_select(symbol, True):\n",
    "            print(f\"Symbol {symbol} is not available.\")\n",
    "            continue\n",
    "\n",
    "        for level, date in days:\n",
    "            # Check if data is missing due to weekends and find last available trading day\n",
    "            if date.weekday() in [5, 6]:  # Saturday or Sunday\n",
    "                date = get_last_trading_day(date)\n",
    "            \n",
    "            # Set the start and end date correctly\n",
    "            start = datetime(date.year, date.month, date.day, 0, 0)  # Start of the day\n",
    "            end = start + timedelta(days=1)  # End of the day\n",
    "\n",
    "            print(f\"Fetching data for {symbol} from {start} to {end}\")\n",
    "\n",
    "            # Fetch rates for the symbol\n",
    "            rates = mt5.copy_rates_range(symbol, mt5.TIMEFRAME_D1, start, end)\n",
    "            \n",
    "            if rates is not None and len(rates) > 0:\n",
    "                # Extract high and low values\n",
    "                high = max(rate['high'] for rate in rates)\n",
    "                low = min(rate['low'] for rate in rates)\n",
    "                results.append({\"Date\": start.date(), \"Symbol\": symbol, \"Highest\": high, \"Lowest\": low, \"Level\": level})\n",
    "            else:\n",
    "                print(f\"No data found for {symbol} on {start.date()}, using previous data\")\n",
    "                last_trading_day = get_last_trading_day(date)\n",
    "                last_start = datetime(last_trading_day.year, last_trading_day.month, last_trading_day.day, 0, 0)\n",
    "                last_end = last_start + timedelta(days=1)\n",
    "                rates = mt5.copy_rates_range(symbol, mt5.TIMEFRAME_D1, last_start, last_end)\n",
    "\n",
    "                if rates is not None and len(rates) > 0:\n",
    "                    high = max(rate['high'] for rate in rates)\n",
    "                    low = min(rate['low'] for rate in rates)\n",
    "                    results.append({\"Date\": last_start.date(), \"Symbol\": symbol, \"Highest\": high, \"Lowest\": low, \"Level\": level})\n",
    "                else:\n",
    "                    results.append({\"Date\": last_start.date(), \"Symbol\": symbol, \"Highest\": None, \"Lowest\": None, \"Level\": level})\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Function to upload data to Google Sheets\n",
    "def upload_to_google_sheets(data, json_path, sheet_name):\n",
    "    \"\"\"\n",
    "    Save the data to Google Sheets.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Authenticate with Google Sheets\n",
    "        gc = gspread.service_account(filename=json_path)\n",
    "        sh = gc.open(sheet_name)\n",
    "        worksheet = sh.sheet1\n",
    "\n",
    "        # Clear old data and write new data\n",
    "        worksheet.clear()\n",
    "        set_with_dataframe(worksheet, data)\n",
    "\n",
    "        print(f\"Data successfully uploaded to Google Sheets: {sh.url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error uploading data to Google Sheets: {e}\")\n",
    "\n",
    "# Main function with continuous updates\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to fetch trading data and upload it to Google Sheets at regular intervals.\n",
    "    \"\"\"\n",
    "    json_path = \"C:/Users/Shaheera/Downloads/live-data-449002-016cfa9e813e.json\"  # Replace with your path\n",
    "    sheet_name = \"live_data_updated\"  # Replace with your Google Sheets name\n",
    "\n",
    "    try:\n",
    "        print(\"Starting continuous data fetch and upload (Press Ctrl+C to stop)...\")\n",
    "        while True:\n",
    "            # Fetch data\n",
    "            trading_data = fetch_trading_data(symbols)\n",
    "\n",
    "            # Upload to Google Sheets\n",
    "            upload_to_google_sheets(trading_data, json_path, sheet_name)\n",
    "\n",
    "            # Wait for 1 minute (adjustable interval)\n",
    "            time.sleep(60)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nProcess stopped by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during execution: {e}\")\n",
    "    finally:\n",
    "        # Shutdown MetaTrader 5 connection\n",
    "        mt5.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5646a-d894-4c17-a4ca-9d3a3f90819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting continuous data fetch and upload (Press Ctrl+C to stop)...\n",
      "Fetching data for XAUUSD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for XAUUSD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for XAUUSD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for BTCUSD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for BTCUSD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for BTCUSD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for BTCEUR from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for BTCEUR from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for BTCEUR from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for ETHUSD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for ETHUSD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for ETHUSD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Symbol SOLUSD is not available.\n",
      "Fetching data for XRPUSD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for XRPUSD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for XRPUSD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for DSHUSD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for DSHUSD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for DSHUSD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for XAUEUR from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for XAUEUR from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for XAUEUR from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for GBPAUD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for GBPAUD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for GBPAUD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for GBPNZD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for GBPNZD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for GBPNZD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for CHFJPY from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for CHFJPY from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for CHFJPY from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for EURJPY from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for EURJPY from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for EURJPY from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for USA30 from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for USA30 from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for USA30 from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for USA100 from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for USA100 from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for USA100 from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for USOIL from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for USOIL from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for USOIL from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for UKOIL from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for UKOIL from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for UKOIL from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for USDJPY from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for USDJPY from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for USDJPY from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for GBPJPY from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for GBPJPY from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for GBPJPY from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for USA500 from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for USA500 from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for USA500 from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for UK100 from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for UK100 from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for UK100 from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for CADJPY from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for CADJPY from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for CADJPY from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for AUDJPY from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for AUDJPY from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for AUDJPY from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for GBPCHF from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for GBPCHF from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for GBPCHF from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for GBPCAD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for GBPCAD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for GBPCAD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for NZDJPY from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for NZDJPY from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for NZDJPY from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for GBPUSD from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for GBPUSD from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for GBPUSD from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Fetching data for EURGBP from 2025-01-31 00:00:00 to 2025-02-01 00:00:00\n",
      "Fetching data for EURGBP from 2025-01-30 00:00:00 to 2025-01-31 00:00:00\n",
      "Fetching data for EURGBP from 2025-01-29 00:00:00 to 2025-01-30 00:00:00\n",
      "Data successfully uploaded to Google Sheets: https://docs.google.com/spreadsheets/d/1UFj0KjxW3KjDSsKaz-89BJfgiYeQ6bLizslfVLwyLDo\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218e92a-c4f1-428a-9db7-53d3e0cb7408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
